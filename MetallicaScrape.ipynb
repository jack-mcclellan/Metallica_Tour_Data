{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f5e2093-0adc-4d3a-aa6d-aced61180dd9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "#function that gets all html pages of past tour events\n",
    "def pages():\n",
    "\n",
    "    #get all pages link\n",
    "    url = 'https://www.metallica.com/tour/past/'\n",
    "    page_lst = []\n",
    "    page_lst.append(url)\n",
    "    loop = True\n",
    "\n",
    "    while loop is True:\n",
    "        result = requests.get(url)\n",
    "        src = result.content\n",
    "        soup = BeautifulSoup(src,'lxml')\n",
    "\n",
    "        #find next page link and create list of links\n",
    "        try:\n",
    "            urls = soup.find('a',{'class':'page-next'})\n",
    "            url = urls.get('href')\n",
    "            page_lst.append(url)\n",
    "        except:\n",
    "            break\n",
    "    return page_lst\n",
    "\n",
    "#add events into a list of events\n",
    "events_lst = []\n",
    "\n",
    "#function to get tour events from each page of past tour events\n",
    "def events(url):\n",
    "\n",
    "    #get contents of html page that contains past tour events\n",
    "    result = requests.get(url)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src,'lxml')\n",
    "\n",
    "    #get all tour event link urls in that page\n",
    "    urls = soup.find_all('a',{'class':'venue-city'})\n",
    "    for x in urls:\n",
    "        events_lst.append(x.get('href'))\n",
    "    return events_lst\n",
    "\n",
    "#create a function to input tour event url and return location, date, setlist\n",
    "def tour_event(url):\n",
    "\n",
    "    #get contents of individual setlist website\n",
    "    result = requests.get(url)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src,'lxml')\n",
    "    \n",
    "    #get location of show\n",
    "    loc = soup.find_all('a',title=re.compile(r'Search for Events in: '))\n",
    "    location = ''\n",
    "    for data in loc:\n",
    "        location += data.text\n",
    "    \n",
    "    #convert to city, state, and country\n",
    "    split_location = location.split(', ')\n",
    "    if len(split_location) == 3:\n",
    "        city = split_location[0]\n",
    "        state = split_location[1]\n",
    "        country = split_location[2]\n",
    "    if len(split_location) == 2:\n",
    "        city = split_location[0]\n",
    "        state = ''\n",
    "        country = split_location[1]\n",
    "    \n",
    "    #if country field has a state inside convert to state and make country united states (2 events have GA/FL as country)\n",
    "    if len(country) == 2:\n",
    "        state = country\n",
    "        country = 'United States'\n",
    "    \n",
    "    #if states are not abbreviated convert to abbreviation\n",
    "    states_abbreivation = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"D.C.\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "    }\n",
    "    if len(state) > 2:\n",
    "        state =  states_abbreivation.get(state)\n",
    "        \n",
    "    #concatenate city, state, and country into new single string\n",
    "    try: \n",
    "        if len(state) == 2:\n",
    "            location = city+', '+state+', '+country\n",
    "    except:\n",
    "        location = city+', '+country\n",
    "    \n",
    "    # get date of show\n",
    "    dat = soup.find_all('h4')\n",
    "    date = ''\n",
    "    for x in dat:\n",
    "        date += x.text\n",
    "    date = re.findall(r'[\\w]+ \\d+, \\d{4}',date)[0]\n",
    "    \n",
    "    #get setlist of show\n",
    "    links = soup.find_all('a',{'class':'songName'})\n",
    "    \n",
    "    #store tour event data in list [date, city, state, country, setlist...]\n",
    "    tour_event_lst = []\n",
    "    \n",
    "    #add date and location to list\n",
    "    tour_event_lst.append(url)\n",
    "    tour_event_lst.append(date)\n",
    "    tour_event_lst.append(location)\n",
    "    tour_event_lst.append(city)\n",
    "    tour_event_lst.append(state)\n",
    "    tour_event_lst.append(country)\n",
    "    \n",
    "    #add setlist to list (no duplicate songs), and add song count to dictionary\n",
    "    for x in links:\n",
    "        if x.text not in tour_event_lst:\n",
    "            tour_event_lst.append(x.text)\n",
    "            songs_lst.append(x.text)\n",
    "    return tour_event_lst\n",
    "\n",
    "#create list of all songs played and dictionary with song title as keys and count of that song as values\n",
    "songs_lst = list()\n",
    "song_counts = {'Song':'Total Plays'}\n",
    "\n",
    "#create csv\n",
    "with open('metallica_scrape.csv','w', newline = '', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    #write headers (longest show ever played was 25 songs long--4/8/1992)\n",
    "    headers = [\n",
    "    'URL', 'Date', 'Location', 'City', 'State', 'Country', 'Song 1', 'Song 2', 'Song 3', 'Song 4', 'Song 5', \n",
    "     'Song 6', 'Song 7', 'Song 8', 'Song 9', 'Song 10', 'Song 11', 'Song 12', 'Song 13', 'Song 14', 'Song 15', \n",
    "     'Song 16', 'Song 17', 'Song 18', 'Song 19', 'Song 20', 'Song 21', 'Song 22','Song 23', 'Song 24', 'Song 25']\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    #for every pages url, get a list of events and add to a master list of all the events...\n",
    "    #... for every event write to csv 'date, city, state, and country and setlist'\n",
    "    for url in pages():\n",
    "        events(url)\n",
    "    for url in events_lst:\n",
    "        writer.writerow(tour_event(url))\n",
    "f.close\n",
    "\n",
    "#add songs from list to dictionary\n",
    "for song in songs_lst:\n",
    "    song_counts[song] = song_counts.get(song, 0) + 1\n",
    "\n",
    "#get summary statistics in different csv\n",
    "with open('metallica_scrape_stats.csv','w', newline = '', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for key, value in song_counts.items():\n",
    "        writer.writerow([key, value])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
